{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iEWU62Y8GDod"
   },
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Kun Wu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tj_WTvO5GDof"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    \n",
    "4. Upload this .HTML file to your Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2019F/blob/master/homework/HM3/HM3.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6EevooumGDog"
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6gkcug2GDoh"
   },
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 199
    },
    "colab_type": "code",
    "id": "Xt34WncxGDoh",
    "outputId": "0189aa27-9f7e-4643-9c45-abeae0f31905"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 3s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ITagzCIpGDol"
   },
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "WPHI_qQ-GDol",
    "outputId": "bae55381-dc2d-4cb3-c02f-3691ba299e73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    return numpy.eye(num_class)[y.reshape(-1)]\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mzAIbpLmGDon"
   },
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGzvlIN6GDoo"
   },
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "S6XrtXh7GDoo",
    "outputId": "ab510b9a-339f-47c1-e396-f14de446b2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FvLlcOJ4GDoq"
   },
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IJSvD6DPGDor"
   },
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "1Yqtp9lFGDor",
    "outputId": "799016d6-257e-4bba-aba2-538ce86aeb27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_65 (Conv2D)           (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_66 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_88 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 592,554\n",
      "Trainable params: 591,914\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.layers import Dropout, BatchNormalization, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "tRmBXr3ULWQE",
    "outputId": "b6db1925-b1a8-4c3a-f1f0-3961fa941f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 64)   256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 64)   256         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 32, 32, 64)   256         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 32, 32, 64)   256         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 32, 32, 64)   0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 32, 32, 64)   0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 64)   36928       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 64)   102464      activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling2D) (None, 32, 32, 3)    0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 32, 32, 64)   256         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 32, 32, 64)   256         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 32, 32, 64)   256         max_pooling2d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 32, 32, 64)   0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 32, 32, 64)   0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 32, 32, 64)   256         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 192)  0           activation_99[0][0]              \n",
      "                                                                 activation_101[0][0]             \n",
      "                                                                 batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)            (None, 196608)       0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 196608)       0           flatten_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 10)           1966090     dropout_54[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,107,530\n",
      "Trainable params: 2,106,890\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "input_img = Input(shape=(32, 32, 3))\n",
    "tower_1 = Conv2D(64, (1,1), padding='same')(input_img)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "tower_1 = Conv2D(64, (3,3), padding='same')(tower_1)\n",
    "tower_1 = BatchNormalization()(tower_1)\n",
    "tower_1 = Activation('relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1,1), padding='same')(input_img)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "tower_2 = Conv2D(64, (5,5), padding='same')(tower_2)\n",
    "tower_2 = BatchNormalization()(tower_2)\n",
    "tower_2 = Activation('relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same')(tower_3)\n",
    "tower_3 = BatchNormalization()(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=3)\n",
    "output = Flatten()(output)\n",
    "output = Dropout(0.5)(output)\n",
    "out = Dense(10, activation='softmax')(output)\n",
    "\n",
    "model_inception = Model(inputs=input_img, outputs=out)\n",
    "model_inception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtbH3CISGDot"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "learning_rate = 1E-3 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "CK5aFOW8GDov",
    "outputId": "2c42455a-9fde-4b30-8fab-5feb4ac16c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1250/1250 [==============================] - 50s 40ms/step - loss: 2.0080 - acc: 0.3125 - val_loss: 1.4536 - val_acc: 0.4685\n",
      "Epoch 2/25\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 1.6266 - acc: 0.4160 - val_loss: 1.4362 - val_acc: 0.4844\n",
      "Epoch 3/25\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 1.4873 - acc: 0.4668 - val_loss: 1.2898 - val_acc: 0.5390\n",
      "Epoch 4/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.3939 - acc: 0.4989 - val_loss: 1.3842 - val_acc: 0.5065\n",
      "Epoch 5/25\n",
      "1250/1250 [==============================] - 45s 36ms/step - loss: 1.3225 - acc: 0.5265 - val_loss: 1.2015 - val_acc: 0.5693\n",
      "Epoch 6/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.2728 - acc: 0.5472 - val_loss: 1.3154 - val_acc: 0.5304\n",
      "Epoch 7/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.2316 - acc: 0.5654 - val_loss: 1.2346 - val_acc: 0.5544\n",
      "Epoch 8/25\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.1945 - acc: 0.5766 - val_loss: 1.1395 - val_acc: 0.5930\n",
      "Epoch 9/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.1601 - acc: 0.5935 - val_loss: 1.1107 - val_acc: 0.6011\n",
      "Epoch 10/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.1324 - acc: 0.6019 - val_loss: 1.0990 - val_acc: 0.6148\n",
      "Epoch 11/25\n",
      "1250/1250 [==============================] - 44s 36ms/step - loss: 1.1105 - acc: 0.6114 - val_loss: 1.1291 - val_acc: 0.6047\n",
      "Epoch 12/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.0908 - acc: 0.6200 - val_loss: 1.0835 - val_acc: 0.6292\n",
      "Epoch 13/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.0795 - acc: 0.6270 - val_loss: 0.9847 - val_acc: 0.6657\n",
      "Epoch 14/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.0524 - acc: 0.6369 - val_loss: 0.9549 - val_acc: 0.6688\n",
      "Epoch 15/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.0381 - acc: 0.6406 - val_loss: 1.1464 - val_acc: 0.6266\n",
      "Epoch 16/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 1.0302 - acc: 0.6438 - val_loss: 0.9677 - val_acc: 0.6711\n",
      "Epoch 17/25\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 1.0237 - acc: 0.6476 - val_loss: 0.9659 - val_acc: 0.6728\n",
      "Epoch 18/25\n",
      "1250/1250 [==============================] - 43s 35ms/step - loss: 1.0058 - acc: 0.6547 - val_loss: 0.8970 - val_acc: 0.6965\n",
      "Epoch 19/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9937 - acc: 0.6608 - val_loss: 0.9436 - val_acc: 0.6779\n",
      "Epoch 20/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9875 - acc: 0.6617 - val_loss: 1.0041 - val_acc: 0.6680\n",
      "Epoch 21/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9797 - acc: 0.6643 - val_loss: 0.9816 - val_acc: 0.6708\n",
      "Epoch 22/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9741 - acc: 0.6641 - val_loss: 0.8768 - val_acc: 0.7041\n",
      "Epoch 23/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9633 - acc: 0.6717 - val_loss: 0.9750 - val_acc: 0.6739\n",
      "Epoch 24/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9664 - acc: 0.6748 - val_loss: 0.8104 - val_acc: 0.7243\n",
      "Epoch 25/25\n",
      "1250/1250 [==============================] - 44s 35ms/step - loss: 0.9560 - acc: 0.6754 - val_loss: 0.9004 - val_acc: 0.6964\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "data_generator.fit(x_tr)\n",
    "\n",
    "history = model.fit(\n",
    "    data_generator.flow(x_tr, y_tr, batch_size=32), \n",
    "    epochs=25, \n",
    "    validation_data=(x_val, y_val)\n",
    ")\n",
    "\n",
    "# history = model.fit(\n",
    "#     x_tr, y_tr, batch_size=32, \n",
    "#     epochs=20, \n",
    "#     validation_data=(x_val, y_val)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 541
    },
    "colab_type": "code",
    "id": "Lt_VFjISGDox",
    "outputId": "da00d7c1-c50c-4fdb-b7d9-dad784f15f76"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwYwPZsAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEGCAYAAABhMDI9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np8ccRU8fujYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "# fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "# fig, axs = plt.subplot(1,2)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# fig = plt.figure(figsize=(14, 6))\n",
    "# plt.subplot(1,2,2)\n",
    "plt.plot(epochs, loss, '-b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, '-r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jS-w19QBGDoz"
   },
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wSHp2Vx8GDoz"
   },
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FXoOewoTGDo0"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1E-4 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "Z8MC4dgJGDo1",
    "outputId": "b0f8487f-cec7-496f-f786-b2a6e95e1ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 57s 37ms/step - loss: 0.9566 - acc: 0.6760\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.9480 - acc: 0.6802\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9467 - acc: 0.6814\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9329 - acc: 0.6838\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9319 - acc: 0.6871\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9274 - acc: 0.6889\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9295 - acc: 0.6906\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9202 - acc: 0.6912\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9148 - acc: 0.6958\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9092 - acc: 0.6960\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9004 - acc: 0.6989\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9038 - acc: 0.7006\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.8988 - acc: 0.7034\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.8964 - acc: 0.7036\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.8903 - acc: 0.7048\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8889 - acc: 0.7069\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8888 - acc: 0.7078\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8834 - acc: 0.7086\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8860 - acc: 0.7081\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8720 - acc: 0.7104\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8758 - acc: 0.7116\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8731 - acc: 0.7137\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8696 - acc: 0.7160\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8717 - acc: 0.7144\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.8675 - acc: 0.7161\n"
     ]
    }
   ],
   "source": [
    "# Augmentation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(\n",
    "#     rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "data_generator.fit(x_train)\n",
    "\n",
    "history = model.fit(\n",
    "    data_generator.flow(x_train, y_train_vec, batch_size=32), \n",
    "    epochs=25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ej-gLUhoGDo3"
   },
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Xht6Tl03GDo4",
    "outputId": "70c69def-a8b0-476b-e8b4-c3f201ce4a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 629us/step\n",
      "loss = 0.9797097798347473\n",
      "accuracy = 0.6867\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOg6ch8hGDo5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HM3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
